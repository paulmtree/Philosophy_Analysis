{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "Text Generation (LSTM).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pkm29/Philosophy_Analysis/blob/master/Text_Generation_(LSTM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q39DZaqcE-c3",
        "colab_type": "text"
      },
      "source": [
        "# Text Generation by Analytics Vidhya\n",
        "source: https://www.analyticsvidhya.com/blog/2018/03/text-generation-using-python-nlp/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x21LvZU4E-c6",
        "colab_type": "text"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8A4nQ7GE-c7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.utils import np_utils\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "#!pip install -U -q PyDrive\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvF_w3zQE-dB",
        "colab_type": "text"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tLQkcNawE-dB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "db02990b-71f4-4ae8-b747-aa4210bbe1d5"
      },
      "source": [
        "try:\n",
        "  sent_df = pd.read_csv(\"sentiment_dataframe.csv\")\n",
        "except:\n",
        "  sent_df = pd.read_csv(\"https://github.com/pkm29/Philosophy_Analysis/raw/master/sentiment_dataframe.csv\")\n",
        "sent_df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>chapter</th>\n",
              "      <th>neg</th>\n",
              "      <th>neu</th>\n",
              "      <th>pos</th>\n",
              "      <th>compound</th>\n",
              "      <th>chapter_text</th>\n",
              "      <th>moving_avg_comp</th>\n",
              "      <th>chapter_author</th>\n",
              "      <th>chapter_text_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>PART ONE  CONTAINING THE PAPERS OF A Are pas...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.814</td>\n",
              "      <td>0.186</td>\n",
              "      <td>0.4939</td>\n",
              "      <td>Preface</td>\n",
              "      <td>0.080093</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Reason alone baptized?</td>\n",
              "      <td>0</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.2500</td>\n",
              "      <td>Preface</td>\n",
              "      <td>0.084089</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Edward Young1 PREFACE  PERHAPS it has sometime...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.083</td>\n",
              "      <td>0.773</td>\n",
              "      <td>0.144</td>\n",
              "      <td>0.6486</td>\n",
              "      <td>Preface</td>\n",
              "      <td>0.084089</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Your life has perhaps brought you into touch w...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.054</td>\n",
              "      <td>0.850</td>\n",
              "      <td>0.096</td>\n",
              "      <td>0.3612</td>\n",
              "      <td>Preface</td>\n",
              "      <td>0.084089</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Perhaps neither case applies to you and your l...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.071</td>\n",
              "      <td>0.857</td>\n",
              "      <td>0.071</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Preface</td>\n",
              "      <td>0.089234</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ... chapter_text_num\n",
              "0      0  ...              NaN\n",
              "1      1  ...              NaN\n",
              "2      2  ...              NaN\n",
              "3      3  ...              NaN\n",
              "4      4  ...              NaN\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x76-1cowE-dF",
        "colab_type": "text"
      },
      "source": [
        "chapter_text_num is NaN only for Preface, this is ok as this column was only created for graphical visualations. Basically just shortened chapter names to numbers. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leNyP1bDE-dG",
        "colab_type": "text"
      },
      "source": [
        "## Creating Word/Character Mappings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAE8YfukE-dH",
        "colab_type": "text"
      },
      "source": [
        "Here are some interesting pros and cons to word vs character mapping highlighted by this [lighttag.io blogpost](https://www.lighttag.io/blog/character-level-NLP/). <br>\n",
        "### Advantages\n",
        "- Character mapping is more general when discerning syntax. With word mapping, words like 3/4\", csv w/, or 50k need to be specified. A regular model usually has the 10-30k most frequent words in its vocabulary, and so \"unusual\" looking words are interpreted poorly. Character mapping sees the input \"as-is\" and each word is equally strange. This is beneficial for poorly spelled, user-generated text as this approach is more generalized and robust. <br>\n",
        "- Due to the smaller vocabulary of character level models, pretraining avoids softmax bottlenecking. Softmax bottlenecking occurs when probability calculations (matrix factorization problems) use such large matrices that the softmax calculations become too difficult to perform. This is a problem faced by recurrent neural networks (RNNs) in general because context of words are incredibly important, leading to much larger matrices, or more specifically, high-rank matrices. A well-known paper by Zhilin Yang in 2018 explores this problem and solution [further](https://arxiv.org/pdf/1711.03953.pdf). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "839De6RUE-dH",
        "colab_type": "text"
      },
      "source": [
        "### Disdvantages\n",
        "- Character mapping loses the semantic content of words, which is oftentimes useful for accuracy purposes. \n",
        "- Character mapping is sometimes more computationally expensive. While character mapping is generally characterized by lower computational costs than word mapping, working at the character level effectively multiplies the length of our sequence by the average number of characters per word. As a result, certain NLP architectures may be necessary to keep computational expenses low. (The lighttag article mentions convolutions or transformers as a way to nullify the cost of long sequences)\n",
        "- The output of character level models requires more work from the user to convert it into words and meaningful insights. Additionally, more work is needed to account for tokenization errors, as character level models split up words into individual charaters and during that process, may interpret words differently than we would like or have a preference for. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMYZ9SgTE-dJ",
        "colab_type": "text"
      },
      "source": [
        "## Character Mapping Approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgDzlb6dE-dK",
        "colab_type": "text"
      },
      "source": [
        "Below we can visualize what is inside of our character mapping. I noticed some weird errors of sentences composed of only numbers and went back to filter them out. Uncomment the last line \"text\" to display the entire text and char_to_n to view the character mapping, I have kept it commented as our notebook output will display the entire thing and be way too large. <br>\n",
        "In this iteration I use the entire book's text. Later on I will try variations such as training seperately on the two authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIF9d1T6E-dL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ebbd0c7e-fec4-4c7a-cfe7-ec68df50c332"
      },
      "source": [
        "#Convert sentences back into book\n",
        "join_with = \" \"\n",
        "text = join_with.join(sent_df[\"sentence\"][sent_df[\"chapter_author\"] == \"Aesthetic\"])\n",
        "text=text.lower()\n",
        "characters = sorted(list(set(text)))\n",
        "n_to_char = {n:char for n, char in enumerate(characters)}\n",
        "char_to_n = {char:n for n, char in enumerate(characters)}\n",
        "#text\n",
        "char_to_n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 0,\n",
              " '!': 1,\n",
              " '&': 2,\n",
              " '(': 3,\n",
              " ')': 4,\n",
              " '*': 5,\n",
              " ',': 6,\n",
              " '-': 7,\n",
              " '.': 8,\n",
              " '/': 9,\n",
              " '0': 10,\n",
              " '1': 11,\n",
              " '2': 12,\n",
              " '3': 13,\n",
              " '4': 14,\n",
              " '5': 15,\n",
              " '6': 16,\n",
              " '7': 17,\n",
              " '8': 18,\n",
              " '9': 19,\n",
              " ':': 20,\n",
              " ';': 21,\n",
              " '?': 22,\n",
              " '[': 23,\n",
              " ']': 24,\n",
              " 'a': 25,\n",
              " 'b': 26,\n",
              " 'c': 27,\n",
              " 'd': 28,\n",
              " 'e': 29,\n",
              " 'f': 30,\n",
              " 'g': 31,\n",
              " 'h': 32,\n",
              " 'i': 33,\n",
              " 'j': 34,\n",
              " 'k': 35,\n",
              " 'l': 36,\n",
              " 'm': 37,\n",
              " 'n': 38,\n",
              " 'o': 39,\n",
              " 'p': 40,\n",
              " 'q': 41,\n",
              " 'r': 42,\n",
              " 's': 43,\n",
              " 't': 44,\n",
              " 'u': 45,\n",
              " 'v': 46,\n",
              " 'w': 47,\n",
              " 'x': 48,\n",
              " 'y': 49,\n",
              " 'z': 50,\n",
              " '\\xa0': 51,\n",
              " 'à': 52,\n",
              " 'ä': 53,\n",
              " 'æ': 54,\n",
              " 'è': 55,\n",
              " 'é': 56,\n",
              " 'ö': 57,\n",
              " 'ø': 58,\n",
              " 'ü': 59,\n",
              " '–': 60,\n",
              " '‘': 61,\n",
              " '’': 62,\n",
              " '“': 63,\n",
              " '”': 64,\n",
              " '…': 65}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3vl1tUSE-dO",
        "colab_type": "text"
      },
      "source": [
        "For the rest of this code I will be following Analytics Vidhya's blogpost by [Pranjal Srivastava](https://www.analyticsvidhya.com/blog/2018/03/text-generation-using-python-nlp/) without including much explanatory text. His descriptions are great and I don't see a reason to copy and paste his explanations if they are already in the article. There are a couple of technical terms that I think are worth explaining further though."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBJ1DXInE-dO",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing for LSTM Training Format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsJfaq3ZE-dP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = []\n",
        "Y = []\n",
        "length = len(text)\n",
        "#seq_length = length of the sequence of characters that we want to consider before predicting a particular character.\n",
        "seq_length = 100\n",
        "for i in range(0, length-seq_length, 1):\n",
        "    sequence = text[i:i + seq_length]\n",
        "    label = text[i + seq_length]\n",
        "    X.append([char_to_n[char] for char in sequence])\n",
        "    Y.append(char_to_n[label])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMcy7_QcE-dS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_modified = np.reshape(X, (len(X), seq_length, 1))\n",
        "X_modified = X_modified / float(len(characters))\n",
        "Y_modified = np_utils.to_categorical(Y)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfslzIp7E-dW",
        "colab_type": "text"
      },
      "source": [
        "## Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBmsjQeaE-dX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sequential model with two LSTM layers having 400 units each\n",
        "model = Sequential()\n",
        "model.add(LSTM(700, input_shape=(X_modified.shape[1], X_modified.shape[2]), return_sequences=True))\n",
        "#20% dropout layer to check for overfitting\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(700, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(700))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(Y_modified.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gatKifLE-db",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4a488fff-dfe1-4961-e706-392c33d590a2"
      },
      "source": [
        "model.fit(X_modified, Y_modified, epochs=24, batch_size=64)\n",
        "#100 epochs, batch size 50, and 3 levels of 700 units and 20% dropout layer\n",
        "model.save_weights('text_generator_e24_bs64_700_0.2_x3.h5')\n",
        "\n",
        "from google.colab import files\n",
        "files.download('text_generator_e24_bs64_700_0.2_x3.h5') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/24\n",
            " 4571/11527 [==========>...................] - ETA: 18:05 - loss: 2.9261"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3InhHGP3Mzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('text_generator_e24_bs64_700_0.2_x3.h5') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8ZM1AbSE-dh",
        "colab_type": "text"
      },
      "source": [
        "## Generating Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbA-QA81E-dh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "string_mapped = X[99]\n",
        "full_string = [n_to_char[value] for value in string_mapped]\n",
        "# generating characters\n",
        "for i in range(seq_length):\n",
        "    x = np.reshape(string_mapped,(1,len(string_mapped), 1))\n",
        "    x = x / float(len(characters))\n",
        "    pred_index = np.argmax(model.predict(x, verbose=0))\n",
        "    seq = [n_to_char[value] for value in string_mapped]\n",
        "    string_mapped.append(pred_index)\n",
        "    string_mapped = string_mapped[1:len(string_mapped)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNvkbTAlE-dl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "txt=\"\"\n",
        "for char in full_string:\n",
        "    txt = txt+char\n",
        "txt"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}